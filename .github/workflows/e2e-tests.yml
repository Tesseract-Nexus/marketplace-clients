name: E2E Tests

on:
  # # Run on push to main branch
  # push:
  #   branches:
  #     - main
  #   paths:
  #     - 'apps/**'
  #     - 'services/**'
  #     - 'packages/**'
  #     - 'playwright.config.ts'
  #     - 'verify-dev-integration.spec.ts'
  #     - '.github/workflows/e2e-tests.yml'

  # # Run on pull requests to main
  # pull_request:
  #   branches:
  #     - main
  #   paths:
  #     - 'apps/**'
  #     - 'services/**'
  #     - 'packages/**'
  #     - 'playwright.config.ts'
  #     - 'verify-dev-integration.spec.ts'

  # Manual trigger
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test against'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
      test_filter:
        description: 'Test filter (regex pattern, leave empty for all tests)'
        required: false
        default: ''
        type: string

  # # Scheduled run - daily at 6 AM UTC
  # schedule:
  #   - cron: '0 6 * * *'

permissions:
  contents: read
  actions: read

env:
  # Default environment URLs
  DEV_ADMIN_URL: https://dev-admin.tesserix.app
  DEV_STORE_URL: https://dev-store.tesserix.app
  STAGING_ADMIN_URL: https://staging-admin.tesserix.app
  STAGING_STORE_URL: https://staging-store.tesserix.app

jobs:
  e2e-tests:
    name: Run E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 300

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        # Version is read from packageManager field in package.json

      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Cache pnpm dependencies
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Determine test environment
        id: env
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENV="${{ github.event.inputs.environment }}"
          else
            ENV="dev"
          fi

          if [ "$ENV" = "staging" ]; then
            echo "BASE_URL=${{ env.STAGING_ADMIN_URL }}" >> $GITHUB_OUTPUT
            echo "STORE_URL=${{ env.STAGING_STORE_URL }}" >> $GITHUB_OUTPUT
          else
            echo "BASE_URL=${{ env.DEV_ADMIN_URL }}" >> $GITHUB_OUTPUT
            echo "STORE_URL=${{ env.DEV_STORE_URL }}" >> $GITHUB_OUTPUT
          fi
          echo "ENV=$ENV" >> $GITHUB_OUTPUT

      - name: Run Playwright tests
        run: |
          FILTER="${{ github.event.inputs.test_filter }}"
          if [ -n "$FILTER" ]; then
            npx playwright test --grep "$FILTER" --reporter=html,github
          else
            npx playwright test --reporter=html,github
          fi
        env:
          BASE_URL: ${{ steps.env.outputs.BASE_URL }}
          STORE_URL: ${{ steps.env.outputs.STORE_URL }}
          CI: true

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report-${{ steps.env.outputs.ENV }}-${{ github.run_number }}
          path: |
            playwright-report/
            test-results/
          retention-days: 30

      - name: Upload test videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-videos-${{ steps.env.outputs.ENV }}-${{ github.run_number }}
          path: test-results/**/*.webm
          retention-days: 7

      - name: Create test summary
        if: always()
        run: |
          echo "## E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ steps.env.outputs.ENV }}" >> $GITHUB_STEP_SUMMARY
          echo "**Base URL:** ${{ steps.env.outputs.BASE_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f test-results/results.json ]; then
            PASSED=$(jq '.stats.expected // 0' test-results/results.json)
            FAILED=$(jq '.stats.unexpected // 0' test-results/results.json)
            SKIPPED=$(jq '.stats.skipped // 0' test-results/results.json)
            DURATION=$(jq '.stats.duration // 0' test-results/results.json)

            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
            echo "| Skipped | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
            echo "| Duration | ${DURATION}ms |" >> $GITHUB_STEP_SUMMARY
          fi

  notify-on-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: failure() && github.event_name == 'schedule'

    steps:
      - name: Create failure issue
        uses: actions/github-script@v7
        with:
          script: |
            const title = `E2E Tests Failed - ${new Date().toISOString().split('T')[0]}`;
            const body = `## Scheduled E2E Tests Failed

            **Workflow Run:** [${context.runId}](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            **Triggered at:** ${new Date().toISOString()}

            Please investigate the test failures and fix any issues.

            ### Quick Links
            - [View Test Report](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            - [Dev Admin Panel](https://dev-admin.tesserix.app)
            `;

            // Check if similar issue exists
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'e2e-failure'
            });

            const existingIssue = issues.data.find(issue =>
              issue.title.startsWith('E2E Tests Failed')
            );

            if (existingIssue) {
              // Add comment to existing issue
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `Another failure detected:\n\n${body}`
              });
            } else {
              // Create new issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['e2e-failure', 'automated']
              });
            }
